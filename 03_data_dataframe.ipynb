{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with DataFrames  (Q and A)\n",
    "\n",
    "Query data with an imperative programming (`Spark Data Frames`) approach and a declarative programming (`Spark SQL`) approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Wrangling Data\") \\\n",
    "    .getOrCreate()\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)\n",
    "\n",
    "\n",
    "# create a view to use for SQL queries for the declarative approach\n",
    "user_log.createOrReplaceTempView(\"user_log_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|       artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page| registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|Showaddywaddy|Logged In|  Kenneth|     M|          112|Matthews|232.93342| paid|Charlotte-Concord...|   PUT|NextSong|1509380319284|     5132|Christmas Tears W...|   200|1513720872284|\"Mozilla/5.0 (Win...|  1046|\n",
      "|   Lily Allen|Logged In|Elizabeth|     F|            7|   Chase|195.23873| free|Shreveport-Bossie...|   PUT|NextSong|1512718541284|     5027|       Cheryl Tweedy|   200|1513720878284|\"Mozilla/5.0 (Win...|  1000|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Which page did user id \"\" (empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            page|\n",
      "+----------------+\n",
      "|           About|\n",
      "|       Downgrade|\n",
      "|           Error|\n",
      "|            Help|\n",
      "|            Home|\n",
      "|           Login|\n",
      "|          Logout|\n",
      "|        NextSong|\n",
      "|   Save Settings|\n",
      "|        Settings|\n",
      "|Submit Downgrade|\n",
      "|  Submit Upgrade|\n",
      "|         Upgrade|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "page_all = user_log.select('page').dropDuplicates().sort('page')\n",
    "page_all.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| page|\n",
      "+-----+\n",
      "|About|\n",
      "| Help|\n",
      "| Home|\n",
      "|Login|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "page_none = user_log.select('page').where(user_log.userId == \"\").dropDuplicates().sort('page')\n",
    "page_none.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Row(page='Downgrade'),\n",
       " Row(page='Error'),\n",
       " Row(page='Logout'),\n",
       " Row(page='NextSong'),\n",
       " Row(page='Save Settings'),\n",
       " Row(page='Settings'),\n",
       " Row(page='Submit Downgrade'),\n",
       " Row(page='Submit Upgrade'),\n",
       " Row(page='Upgrade')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(page_all.collect())-set(page_none.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|page|            page|\n",
      "+----+----------------+\n",
      "|null|Submit Downgrade|\n",
      "|null|       Downgrade|\n",
      "|null|          Logout|\n",
      "|null|   Save Settings|\n",
      "|null|        Settings|\n",
      "|null|        NextSong|\n",
      "|null|         Upgrade|\n",
      "|null|           Error|\n",
      "|null|  Submit Upgrade|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL\n",
    "spark.sql(\"\"\"\n",
    "          SELECT * \n",
    "            FROM ( \n",
    "                SELECT DISTINCT page \n",
    "                FROM user_log_table \n",
    "                WHERE userID='') AS user_pages \n",
    "            RIGHT JOIN ( \n",
    "                SELECT DISTINCT page \n",
    "                FROM user_log_table) AS all_pages \n",
    "            ON user_pages.page = all_pages.page \n",
    "            WHERE user_pages.page IS NULL\n",
    "         \"\"\"\n",
    "         ).show() #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|     F| 3820|\n",
      "|  null|  336|\n",
      "|     M| 5844|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_log.groupby(\"gender\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log.select('userId', 'gender').filter(user_log.gender == 'F').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Count|\n",
      "+-----+\n",
      "|  462|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\n",
    "        \"\"\"\n",
    "        SELECT COUNT(DISTINCT userID) as Count \n",
    "        FROM user_log_table \\\n",
    "        WHERE gender = 'F'\n",
    "        \"\"\"\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              artist|count|\n",
      "+--------------------+-----+\n",
      "|                null| 1653|\n",
      "|            Coldplay|   83|\n",
      "|       Kings Of Leon|   69|\n",
      "|Florence + The Ma...|   52|\n",
      "|            BjÃÂ¶rk|   46|\n",
      "|       Dwight Yoakam|   45|\n",
      "|       Justin Bieber|   43|\n",
      "|      The Black Keys|   40|\n",
      "|         OneRepublic|   37|\n",
      "|                Muse|   36|\n",
      "|        Jack Johnson|   36|\n",
      "|           Radiohead|   31|\n",
      "|        Taylor Swift|   29|\n",
      "|          Lily Allen|   28|\n",
      "|               Train|   28|\n",
      "|Barry Tuckwell/Ac...|   28|\n",
      "|          Nickelback|   27|\n",
      "|           Daft Punk|   27|\n",
      "|           Metallica|   27|\n",
      "|          Kanye West|   26|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col\n",
    "user_log.select(\"artist\").groupby('artist').count().sort(col('count').desc()).show()\n",
    "#user_log.select(\"page\").dropDuplicates().sort(\"page\").show()\n",
    "#user_log.where(user_log.page == \"NextSong\").groupby(user_log.hour).count().orderBy(user_log.hour.cast(\"float\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  artist|count|\n",
      "+--------+-----+\n",
      "|    null| 1653|\n",
      "|Coldplay|   83|\n",
      "+--------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.select(\"artist\").groupby('artist').count().sort(col('count').desc()).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  Artist|Count|\n",
      "+--------+-----+\n",
      "|Coldplay|   83|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\n",
    "        \"\"\"\n",
    "        SELECT Artist, COUNT(Artist) AS Count \\\n",
    "        FROM user_log_table \\\n",
    "        GROUP BY Artist \\\n",
    "        ORDER BY Count DESC \\\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How many songs does the most played artist have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|  artist|                song|\n",
      "+--------+--------------------+\n",
      "|Coldplay|       The Scientist|\n",
      "|Coldplay|          One I Love|\n",
      "|Coldplay|             Fix You|\n",
      "|Coldplay|        See You Soon|\n",
      "|Coldplay|     Bigger Stronger|\n",
      "|Coldplay|    Strawberry Swing|\n",
      "|Coldplay|A Rush Of Blood T...|\n",
      "|Coldplay|      Glass Of Water|\n",
      "|Coldplay|               Lost!|\n",
      "|Coldplay|        Warning Sign|\n",
      "|Coldplay|             Trouble|\n",
      "|Coldplay|Everything's Not ...|\n",
      "|Coldplay|                 Yes|\n",
      "|Coldplay|              Clocks|\n",
      "|Coldplay|              Shiver|\n",
      "|Coldplay|Now My Feet Won't...|\n",
      "|Coldplay|          I Ran Away|\n",
      "|Coldplay|              Yellow|\n",
      "|Coldplay|    Til Kingdom Come|\n",
      "|Coldplay| Life In Technicolor|\n",
      "|Coldplay|         In My Place|\n",
      "|Coldplay|            Daylight|\n",
      "|Coldplay|God Put A Smile U...|\n",
      "|Coldplay|       White Shadows|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.select(['artist','song']).filter(user_log.artist == \"Coldplay\").dropDuplicates().show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log.select('song').filter(user_log.artist == \"Coldplay\").dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+\n",
      "|  Artist|PlayCount|SongCount|\n",
      "+--------+---------+---------+\n",
      "|Coldplay|       83|       24|\n",
      "+--------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\n",
    "        \"\"\"\n",
    "        SELECT Artist, COUNT(Artist) AS PlayCount, COUNT(DISTINCT song) AS SongCount \\\n",
    "        FROM user_log_table \\\n",
    "        GROUP BY Artist \\\n",
    "        ORDER BY PlayCount DESC \\\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both (1) `Spark Data Frames` and (2) `Spark SQL` are part of the Spark SQL library. Since the syntax is clearer and can be shared with a wider community (since many analysts and data scientist prefer using SQL) and Spark automatically optimize the SQL code to speed up the process of manipulating and retrieving data, I prefer SQL over Data frames, but Spark Data Frames give more control such as breaking down the queries into smaller steps, which can make debugging easier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
